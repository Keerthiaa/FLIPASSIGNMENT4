{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function tO search details of most viewed videos on YouTube from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostviewed_videos():\n",
    "    \n",
    "    URL = 'https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'#URL for accessing the website\n",
    "    \n",
    "    driver=webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver.exe\") #Calling the Web Driver\n",
    "    driver.get(URL) #Opening with the URL template\n",
    "    driver.maximize_window() #Maximize the Window\n",
    "    \n",
    "    details = [] #Declaring a Dummy list for storing the details\n",
    "    \n",
    "    for i in driver.find_elements_by_xpath(\"//table [@class = 'wikitable sortable jquery-tablesorter']/tbody/tr/td\"):\n",
    "        details.append(i.text)\n",
    "        \n",
    "    driver.close() #Exiting the driver post scraping the information\n",
    "    \n",
    "    details= details[:180] #Removing the unwanted details from the list\n",
    "    \n",
    "    Rank = [] \n",
    "    Name = [] \n",
    "    Artist = [] \n",
    "    Views = [] \n",
    "    Upload_date = [] \n",
    "\n",
    "    z= 0\n",
    "    while z < len(details): # Splitting the collected table details and storing the details appropriately\n",
    "        Rank.append(details[z])\n",
    "        z+=1\n",
    "        Name.append(details[z])\n",
    "        z+=1\n",
    "        Artist.append(details[z])\n",
    "        z+=1\n",
    "        Views.append(details[z])\n",
    "        z+=1\n",
    "        Upload_date.append(details[z])\n",
    "        z+=2\n",
    "    \n",
    "    #Creating the DataFrame from all collected data\n",
    "    table = pd.DataFrame({\"Rank\" : Rank,\n",
    "                          \"Name\" : Name, \n",
    "                          \"Artist\" : Artist,\n",
    "                          \"Upload date\" : Upload_date,\n",
    "                          \"Views\" : Views\n",
    "    })        \n",
    "    \n",
    "    \n",
    "    return table#returns the DataFrame with collected details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostviewed = mostviewed_videos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[22]</td>\n",
       "      <td>Pinkfong Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>8.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[24]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>7.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Shape of You\"[25]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[26]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>5.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"See You Again\"[27]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"Masha and the Bear ‚Äì Recipe for Disaster\"[30]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Uptown Funk\"[31]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Gangnam Style\"[32]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Learning Colors ‚Äì Colorful Eggs on a Farm\"[34]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Bath Song\"[35]</td>\n",
       "      <td>Cocomelon ‚Äì Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>3.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[36]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>3.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Sugar\"[37]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Sorry\"[38]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Roar\"[39]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Dame Tu Cosita\"[40]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[41]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Thinking Out Loud\"[42]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Dark Horse\"[43]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Faded\"[44]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Shake It Off\"[45]</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>August 18, 2014</td>\n",
       "      <td>3.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Lean On\"[46]</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Bailando\"[47]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Girls Like You\"[48]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Let Her Go\"[49]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>2.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Wheels on the Bus\"[50]</td>\n",
       "      <td>Cocomelon ‚Äì Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Mi Gente\"[51]</td>\n",
       "      <td>J Balvin</td>\n",
       "      <td>June 29, 2017</td>\n",
       "      <td>2.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Perfect\"[52]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>2.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Hello\"[53]</td>\n",
       "      <td>Adele</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>2.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[54]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>2.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Axel F\"[55]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>2.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0    1.                           \"Baby Shark Dance\"[22]   \n",
       "1    2.                                  \"Despacito\"[24]   \n",
       "2    3.                               \"Shape of You\"[25]   \n",
       "3    4.                       \"Johny Johny Yes Papa\"[26]   \n",
       "4    5.                              \"See You Again\"[27]   \n",
       "5    6.   \"Masha and the Bear ‚Äì Recipe for Disaster\"[30]   \n",
       "6    7.                                \"Uptown Funk\"[31]   \n",
       "7    8.                              \"Gangnam Style\"[32]   \n",
       "8    9.  \"Learning Colors ‚Äì Colorful Eggs on a Farm\"[34]   \n",
       "9   10.                                  \"Bath Song\"[35]   \n",
       "10  11.                \"Phonics Song with Two Words\"[36]   \n",
       "11  12.                                      \"Sugar\"[37]   \n",
       "12  13.                                      \"Sorry\"[38]   \n",
       "13  14.                                       \"Roar\"[39]   \n",
       "14  15.                             \"Dame Tu Cosita\"[40]   \n",
       "15  16.                             \"Counting Stars\"[41]   \n",
       "16  17.                          \"Thinking Out Loud\"[42]   \n",
       "17  18.                                 \"Dark Horse\"[43]   \n",
       "18  19.                                      \"Faded\"[44]   \n",
       "19  20.                               \"Shake It Off\"[45]   \n",
       "20  21.                                    \"Lean On\"[46]   \n",
       "21  22.                                   \"Bailando\"[47]   \n",
       "22  23.                             \"Girls Like You\"[48]   \n",
       "23  24.                                 \"Let Her Go\"[49]   \n",
       "24  25.                          \"Wheels on the Bus\"[50]   \n",
       "25  26.                                   \"Mi Gente\"[51]   \n",
       "26  27.                                    \"Perfect\"[52]   \n",
       "27  28.                                      \"Hello\"[53]   \n",
       "28  29.           \"Waka Waka (This Time for Africa)\"[54]   \n",
       "29  30.                                     \"Axel F\"[55]   \n",
       "\n",
       "                            Artist        Upload date Views  \n",
       "0   Pinkfong Kids' Songs & Stories      June 17, 2016  8.50  \n",
       "1                       Luis Fonsi   January 12, 2017  7.33  \n",
       "2                       Ed Sheeran   January 30, 2017  5.30  \n",
       "3                      LooLoo Kids    October 8, 2016  5.27  \n",
       "4                      Wiz Khalifa      April 6, 2015  5.09  \n",
       "5                       Get Movies   January 31, 2012  4.43  \n",
       "6                      Mark Ronson  November 19, 2014  4.17  \n",
       "7                              Psy      July 15, 2012  4.06  \n",
       "8                      Miroshka TV  February 27, 2018  4.01  \n",
       "9       Cocomelon ‚Äì Nursery Rhymes        May 2, 2018  3.99  \n",
       "10                       ChuChu TV      March 6, 2014  3.81  \n",
       "11                        Maroon 5   January 14, 2015  3.45  \n",
       "12                   Justin Bieber   October 22, 2015  3.43  \n",
       "13                      Katy Perry  September 5, 2013  3.34  \n",
       "14                       El Chombo      April 5, 2018  3.30  \n",
       "15                     OneRepublic       May 31, 2013  3.28  \n",
       "16                      Ed Sheeran    October 7, 2014  3.25  \n",
       "17                      Katy Perry  February 20, 2014  3.06  \n",
       "18                     Alan Walker   December 3, 2015  3.05  \n",
       "19                    Taylor Swift    August 18, 2014  3.05  \n",
       "20            Major Lazer Official     March 22, 2015  3.03  \n",
       "21                Enrique Iglesias     April 11, 2014  3.02  \n",
       "22                        Maroon 5       May 31, 2018  3.02  \n",
       "23                       Passenger      July 25, 2012  2.98  \n",
       "24      Cocomelon ‚Äì Nursery Rhymes       May 24, 2018  2.94  \n",
       "25                        J Balvin      June 29, 2017  2.91  \n",
       "26                      Ed Sheeran   November 9, 2017  2.83  \n",
       "27                           Adele   October 22, 2015  2.83  \n",
       "28                         Shakira       June 4, 2010  2.81  \n",
       "29                      Crazy Frog      June 16, 2009  2.78  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostviewed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape the details team India‚Äôs international fixtures from bcci.tv. Url = https://www.bcci.tv/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def India_fixtures():\n",
    "    \"\"\"Creating function that searches details of Team India International Fixtures\"\"\"\n",
    "\n",
    "    URL = 'https://www.bcci.tv/.' #URL template for accessing the website\n",
    "    \n",
    "    driver=webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver.exe\") #Calling the Web Driver    \n",
    "    driver.get(URL) #Opening with the URL template\n",
    "    driver.maximize_window() #Maximize the Window\n",
    "    \n",
    "    time.sleep(5) #Making the Function wait for 5sec so webpage will open\n",
    "    \n",
    "    #Creating a variable \"Button\" to search the Fixtures and getting the 'href' to open in the driver.\n",
    "    button = driver.find_element_by_xpath(\"//div[@class = 'navigation__drop-down drop-down drop-down--reveal-on-hover']/div/ul/li/a\")\n",
    "    driver.get(button.get_attribute(\"href\"))\n",
    "    \n",
    "    time.sleep(5) #Making the Function wait for 5sec so webpage will open\n",
    "    \n",
    "    Match_title = [] #Creating Variable Match title to collect the title of the match i.e. Test or ODI.\n",
    "    Series = [] #Creating Variable Series to collect the Series name. \n",
    "    Place = [] #Creating variable Place to collect the Match venue.\n",
    "    Date = [] #Creating Variable Date to collect the venue Date.\n",
    "    Time = [] #Creating Variable Time to collect the venue Time.\n",
    "    details = [] #Creating a Dummy variable Details to collect the Date and time details\n",
    "    \n",
    "    #Scraping Match Details and appending in the Match list.\n",
    "    for i in driver.find_elements_by_xpath(\"//div [@class = 'fixture__format-strip']/ span [@class = 'u-unskewed-text fixture__format']\"):\n",
    "        Match_title.append(i.text)\n",
    "\n",
    "    #Scraping Series Details and appending in the Series list.    \n",
    "    for i in driver.find_elements_by_xpath(\"//div [@class = 'fixture__format-strip']/ span [@class = 'u-unskewed-text fixture__tournament-label u-truncated']\"):\n",
    "        Series.append(i.text)\n",
    "    \n",
    "    #Scraping Place Details and appending in the Place list.\n",
    "    for i in driver.find_elements_by_xpath(\"//div [@class = 'fixture__description u-unskewed-text']/p/span\"):\n",
    "        Place.append(i.text)\n",
    "    \n",
    "    #Scraping Date and Time Details and appending in the details list.\n",
    "    for i in driver.find_elements_by_xpath(\"//div [@class = 'fixture__datetime desktop-only']\"):\n",
    "        details.append(i.text.replace('\\n',' '))\n",
    "        \n",
    "    driver.close() #Exiting the driver post scraping the information    \n",
    "    \n",
    "    #Spliting the details list and sorting it in Date and Time. \n",
    "    Date = [i.split(' ',3)[:3]for i in details]\n",
    "    Date = [' '.join(i) for i in Date]\n",
    "    Time = [i.split(' ',3)[-1]for i in details]\n",
    "    \n",
    "    #Creating the DataFrame from all collected data\n",
    "    Fixtures = pd.DataFrame({'Match title' : Match_title , \n",
    "                             'Series' : Series , \n",
    "                             'Place' : Place, \n",
    "                             'Date' : Date ,\n",
    "                             'Time' : Time})\n",
    "    \n",
    "    return Fixtures #returns the DataFrame with collected details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST</td>\n",
       "      <td>ICC WORLD TEST CHAMPIONSHIP FINAL</td>\n",
       "      <td>The Ageas Bowl, Southampton</td>\n",
       "      <td>Friday 18 JUNE</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Trent Bridge, Nottingham</td>\n",
       "      <td>Wednesday 04 AUGUST</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Lord's, London</td>\n",
       "      <td>Thursday 12 AUGUST</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Headingley, Leeds</td>\n",
       "      <td>Wednesday 25 AUGUST</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>The Oval, London</td>\n",
       "      <td>Thursday 02 SEPTEMBER</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TEST</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Old Trafford, Manchester</td>\n",
       "      <td>Friday 10 SEPTEMBER</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Match title                             Series                        Place  \\\n",
       "0        TEST  ICC WORLD TEST CHAMPIONSHIP FINAL  The Ageas Bowl, Southampton   \n",
       "1        TEST               ENGLAND V INDIA 2021     Trent Bridge, Nottingham   \n",
       "2        TEST               ENGLAND V INDIA 2021               Lord's, London   \n",
       "3        TEST               ENGLAND V INDIA 2021            Headingley, Leeds   \n",
       "4        TEST               ENGLAND V INDIA 2021             The Oval, London   \n",
       "5        TEST               ENGLAND V INDIA 2021     Old Trafford, Manchester   \n",
       "\n",
       "                    Date       Time  \n",
       "0         Friday 18 JUNE  15:30 IST  \n",
       "1    Wednesday 04 AUGUST  15:30 IST  \n",
       "2     Thursday 12 AUGUST  15:30 IST  \n",
       "3    Wednesday 25 AUGUST  15:30 IST  \n",
       "4  Thursday 02 SEPTEMBER  15:30 IST  \n",
       "5    Friday 10 SEPTEMBER  15:30 IST  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "India_fixtures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape the details of selenium exception from guru99.com. Url = https://www.guru99.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Selenium_exp_handeling():\n",
    "\n",
    "    template = 'https://www.guru99.com' #URL template for accessing the website.\n",
    "    driver=webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver.exe\") #Calling the Web Driver    \n",
    "\n",
    "    driver.get(template) #Opening with the URL template.\n",
    "    driver.maximize_window() #Maximize the Window.\n",
    "    \n",
    "    href = [] #Creating a variable to collect the href details of Selenium.\n",
    "    for i in driver.find_elements_by_xpath(\"//li [@class = 'fa fa-chevron-circle-right']/a\"):\n",
    "        if i.text == 'Selenium':\n",
    "            href.append(i.get_attribute('href'))\n",
    "        \n",
    "    driver.get(href[0]) #Opening the Driver with the href details.\n",
    "    \n",
    "    #Finding the 'Selenium Exception Handling' tutorial and clicking.\n",
    "    tutorial = driver.find_element_by_xpath(\"//td [@class = 'responsivetable']/a [@title = 'Selenium Exception Handling (Common Exceptions List)']\")\n",
    "    tutorial.click()\n",
    "    \n",
    "    time.sleep(3)#Making the Function wait for 3sec so webpage will open.\n",
    "\n",
    "    details = [] #Creating a Variable name Details to collect the Details of Name and Description Note.\n",
    "    \n",
    "    #Scraping the Details of Name and Description Note and storing it in the details.\n",
    "    for i in driver.find_elements_by_xpath(\"//table [@class = 'table table-striped']/tbody\"):\n",
    "        details.append(i.text)\n",
    "    \n",
    "    driver.close()#Closing the Driver post collecting the informations.\n",
    "     #Splitting the Details list and storing it in name and Description_Note.\n",
    "    details =  [i.split('\\n') for i in details]\n",
    "    \n",
    "    details = details[0]\n",
    "    details.remove('Exception name Description')\n",
    "    \n",
    "    Name =  [i.split(' ',1)[0] for i in details]\n",
    "    Description_Note = [i.split(' ',1)[-1] for i in details]\n",
    "    \n",
    "    #Creating the DataFrame from all collected data.\n",
    "    exception_handeling = pd.DataFrame({'Name' : Name,\n",
    "                                        'Description Note' : Description_Note})\n",
    "    \n",
    "    return exception_handeling #returns the DataFrame with collected details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description Note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ElementNotVisibleException</td>\n",
       "      <td>This type of Selenium exception occurs when an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ElementNotSelectableException</td>\n",
       "      <td>This Selenium exception occurs when an element...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NoSuchElementException</td>\n",
       "      <td>This Exception occurs if an element could not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NoSuchFrameException</td>\n",
       "      <td>This Exception occurs if the frame target to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoAlertPresentException</td>\n",
       "      <td>This Exception occurs when you switch to no pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NoSuchWindowException</td>\n",
       "      <td>This Exception occurs if the window target to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>StaleElementReferenceException</td>\n",
       "      <td>This Selenium exception occurs happens when th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SessionNotFoundException</td>\n",
       "      <td>The WebDriver is acting after you quit the bro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TimeoutException</td>\n",
       "      <td>Thrown when there is not enough time for a com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WebDriverException</td>\n",
       "      <td>This Exception takes place when the WebDriver ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Name  \\\n",
       "0      ElementNotVisibleException   \n",
       "1   ElementNotSelectableException   \n",
       "2          NoSuchElementException   \n",
       "3            NoSuchFrameException   \n",
       "4         NoAlertPresentException   \n",
       "5           NoSuchWindowException   \n",
       "6  StaleElementReferenceException   \n",
       "7        SessionNotFoundException   \n",
       "8                TimeoutException   \n",
       "9              WebDriverException   \n",
       "\n",
       "                                    Description Note  \n",
       "0  This type of Selenium exception occurs when an...  \n",
       "1  This Selenium exception occurs when an element...  \n",
       "2  This Exception occurs if an element could not ...  \n",
       "3  This Exception occurs if the frame target to b...  \n",
       "4  This Exception occurs when you switch to no pr...  \n",
       "5  This Exception occurs if the window target to ...  \n",
       "6  This Selenium exception occurs happens when th...  \n",
       "7  The WebDriver is acting after you quit the bro...  \n",
       "8  Thrown when there is not enough time for a com...  \n",
       "9  This Exception takes place when the WebDriver ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exeptions = Selenium_exp_handeling() #Calling the Function and storing it in a variable.\n",
    "exeptions.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape the details of State-wise GDP of India from statisticstime.com. Url = http://statisticstimes.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def State_wise_GDP():\n",
    "    template = 'http://statisticstimes.com/'#URL template for accessing the website.\n",
    "    driver=webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver.exe\") #Calling the Web Driver    \n",
    "\n",
    "    driver.get(template) #Opening with the URL template.\n",
    "    driver.maximize_window() #Maximize the Window.\n",
    "    \n",
    "    href = [] #Declaring the list href to scrap all the href details\n",
    "    for i in driver.find_elements_by_xpath(\"//div [@class = 'dropdown']/div [@class = 'dropdown-content']/a\"):\n",
    "        href.append(i.get_attribute('href'))\n",
    "        \n",
    "    driver.get(href[4]) #opening the href[4] which is GDP of India.\n",
    "    \n",
    "    href = [] #Declaring the list href to scrap all the href details of GDP of Indian states.\n",
    "    for i in driver.find_elements_by_xpath(\"//div [@style = 'float:left;background-color:seashell;width:400px;height:800px;']/ul [@style = 'list-style-type:none;margin-left:20px;']/li/a\"):\n",
    "        if i.text == '¬ª GDP of Indian states':\n",
    "            href.append(i.get_attribute('href'))\n",
    "    \n",
    "    driver.get(href[0]) #opening the href[4] which is GDP of Indian states.\n",
    "    \n",
    "    Rank = [] #Declaring Rank list to collect the Rank details\n",
    "    State = [] #Declaring State list to collect the State details\n",
    "    GSDP20 = [] #Declaring GSDP20 list to collect the GSDP20 details\n",
    "    GSDP19 = [] #Declaring GSDP19 list to collect the GSDP19 details\n",
    "    Share = [] #Declaring Share list to collect the Share details\n",
    "    GDP = [] #Declaring GDP list to collect the GDP details\n",
    "\n",
    "    details = [] #scraping all the above mentioned details and storing it in the details list.\n",
    "    for i in driver.find_elements_by_xpath(\"//tbody /tr [@role = 'row']/td\"):\n",
    "        details.append(i.text)\n",
    "    \n",
    "    driver.close() #Exiting the Driver post collecting all the details.\n",
    "    \n",
    "    details = details[:264] #Sorting the list with the required details.\n",
    "    \n",
    "    z= 0\n",
    "    while z < len(details): # Splitting the collected details and storing it in the required list.\n",
    "        Rank.append(details[z])\n",
    "        z+=1\n",
    "        State.append(details[z])\n",
    "        z+=1\n",
    "        GSDP20.append(details[z])\n",
    "        z+=1\n",
    "        GSDP19.append(details[z])\n",
    "        z+=1\n",
    "        Share.append(details[z])\n",
    "        z+=1\n",
    "        GDP.append(details[z])\n",
    "        z+=3\n",
    "    \n",
    "    #Creating a DataFrame with collected details.\n",
    "    table = pd.DataFrame({\"Rank\" : Rank,\n",
    "                          \"State\" : State,\n",
    "                          \"GSDP(19-20)\" : GSDP20,\n",
    "                          \"GSDP(18-19)\" : GSDP19,\n",
    "                          \"Share(2018)\" : Share,\n",
    "                          \"GDP($ billion)\": GDP})\n",
    "    \n",
    "    return table #returing the dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(19-20)</th>\n",
       "      <th>GSDP(18-19)</th>\n",
       "      <th>Share(2018)</th>\n",
       "      <th>GDP($ billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.88%</td>\n",
       "      <td>398.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.59%</td>\n",
       "      <td>246.529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.35%</td>\n",
       "      <td>239.656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.92%</td>\n",
       "      <td>227.276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.87%</td>\n",
       "      <td>225.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.75%</td>\n",
       "      <td>164.820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.97%</td>\n",
       "      <td>142.543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.55%</td>\n",
       "      <td>130.501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.54%</td>\n",
       "      <td>130.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.27%</td>\n",
       "      <td>122.431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank           State GSDP(19-20) GSDP(18-19) Share(2018) GDP($ billion)\n",
       "0    1     Maharashtra           -   2,632,792      13.88%        398.145\n",
       "1    2      Tamil Nadu   1,845,853   1,630,208       8.59%        246.529\n",
       "2    3   Uttar Pradesh   1,687,818   1,584,764       8.35%        239.656\n",
       "3    4         Gujarat           -   1,502,899       7.92%        227.276\n",
       "4    5       Karnataka   1,631,977   1,493,127       7.87%        225.798\n",
       "5    6     West Bengal   1,253,832   1,089,898       5.75%        164.820\n",
       "6    7       Rajasthan   1,020,989     942,586       4.97%        142.543\n",
       "7    8  Andhra Pradesh     972,782     862,957       4.55%        130.501\n",
       "8    9       Telangana     969,604     861,031       4.54%        130.210\n",
       "9   10  Madhya Pradesh     906,672     809,592       4.27%        122.431"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDP = State_wise_GDP() #Calling the function and storing it in a variable.\n",
    "GDP.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape the details of trending repositories on Github.com. Url = https://github.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trending_rep():\n",
    "    \"\"\"Creating function that searches details of GITHUB trendings repository\"\"\"\n",
    "    \n",
    "    template = 'https://github.com/' #URL template for accessing the website.\n",
    "    driver=webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver.exe\") #Calling the Web Driver    \n",
    "\n",
    "    driver.get(template) #Opening with the URL template.\n",
    "    driver.maximize_window()#Maximize the Window.\n",
    "    time.sleep(5)#Making the Function wait for 3sec so webpage will open.\n",
    "    \n",
    "    #Searching the button trending and calling it in the web Driver.\n",
    "    button = driver.find_element_by_xpath(\"//ul [@class= 'list-style-none mb-3']/li [@class = 'edge-item-fix']/a [@data-ga-click = '(Logged out) Header, go to Trending']\")\n",
    "    driver.get(button.get_attribute('href'))\n",
    "    time.sleep(1) #Making the Function wait for 1sec so webpage will open.\n",
    "    \n",
    "    href = [] #Declaring the list href to scrap all the href details of trending repository.\n",
    "    for i in driver.find_elements_by_xpath(\"//h1 [@class = 'h3 lh-condensed']/a\"):\n",
    "        href.append(i.get_attribute('href'))\n",
    "        \n",
    "                    \n",
    "    driver.close() #Closing the Driver post collecting the Required Details.\n",
    "    Repository_title = [] #Creating Repository_title list to collect the Repository_title details.\n",
    "    Repository_description = [] #Creating Repository_description list to collect the Repository_description details.\n",
    "    Contributors_count = [] #Creating Contributors_count list to collect the Contributors_count details.\n",
    "    Language_used = [] #Creating Language_used list to collect the Language_used details.\n",
    "    \n",
    "    for i in href:#Iterating all the href and scraping the required details.\n",
    "        driver=webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver.exe\") #Calling the Web Driver    \n",
    "\n",
    "        driver.get(i)#Opening with the iterating href details.\n",
    "        driver.maximize_window()#Maximize the Window.\n",
    "        time.sleep(2) #Making the Function wait for 1sec so webpage will open.\n",
    "        \n",
    "        #Scraping the Repository_title\n",
    "        tit = driver.find_element_by_xpath(\"//h1 [@class = ' d-flex flex-wrap flex-items-center break-word f3 text-normal']\")\n",
    "        Repository_title.append(tit.text.replace('\\n', ' '))\n",
    "        \n",
    "        #Scraping the Repository_description.\n",
    "        try:\n",
    "            des = driver.find_element_by_xpath(\"//div [@class = 'BorderGrid-cell']/p [@class = 'f4 mt-3']\")\n",
    "            Repository_description.append(des.text)\n",
    "        except:\n",
    "            Repository_description.append(\"-\")\n",
    "        \n",
    "        #Scraping the Contributors_count.\n",
    "        count = [] #Creating a Dummy Variable to collect the appropriate Contributors_count details.\n",
    "        try:\n",
    "            for i in driver.find_elements_by_xpath(\"//h2 [@class = 'h4 mb-3']//span [@class = 'Counter ']\"):\n",
    "                count.append(i.get_attribute('title'))\n",
    "            Contributors_count.append(count[-1])\n",
    "        except:\n",
    "            Contributors_count.append('1')\n",
    "                \n",
    "        #Scraping the Language_used.\n",
    "        lang = [] #Creating a Dummy Variable to collect the appropriate Language_used details.\n",
    "        for i in driver.find_elements_by_xpath(\"//ul [@class = 'list-style-none']/li [@class = 'd-inline']//span\"):\n",
    "            lang.append(i.text)\n",
    "        if (\" \".join(lang)) == '':\n",
    "            Language_used.append('-')\n",
    "        else:\n",
    "            Language_used.append(\" \".join(lang))\n",
    "        \n",
    "        driver.close() #Quiting the Driver post scraping the Details.\n",
    "    \n",
    "    \n",
    "    #Creating the DataFrame with the collected details.\n",
    "    table = pd.DataFrame({\"Repository title\" : Repository_title,\n",
    "                          \"Repository description\" : Repository_description,\n",
    "                          \"Contributors count\" : Contributors_count,\n",
    "                          \"Language used\" : Language_used})\n",
    "    \n",
    "    return table #returing the DataFrame Created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Repository description</th>\n",
       "      <th>Contributors count</th>\n",
       "      <th>Language used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abuanwar072 / Flutter-Responsive-Admin-Panel-o...</td>\n",
       "      <td>Responsive Admin Panel or Dashboard using Flutter</td>\n",
       "      <td>0</td>\n",
       "      <td>Dart 82.7% Ruby 8.3% HTML 4.6% Swift 3.9% Othe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pyston / pyston</td>\n",
       "      <td>A faster and highly-compatible implementation ...</td>\n",
       "      <td>2</td>\n",
       "      <td>Python 63.0% C 34.1% C++ 1.3% HTML 0.4% M4 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>slidevjs / slidev</td>\n",
       "      <td>Presentation Slides for Developers (Public Bet...</td>\n",
       "      <td>11</td>\n",
       "      <td>TypeScript 58.5% Vue 29.5% CSS 5.8% JavaScript...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pallupz / covid-vaccine-booking</td>\n",
       "      <td>This very basic script can be used to automate...</td>\n",
       "      <td>10</td>\n",
       "      <td>Python 100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>youngyangyang04 / leetcode-master</td>\n",
       "      <td>LeetCode Âà∑È¢òÊîªÁï•Ôºö200ÈÅìÈ¢òÁõÆËØ¶ÁªÜÂà∑È¢òÈ°∫Â∫èÔºåÂÖ±60wÂ≠óÁöÑËØ¶ÁªÜÂõæËß£ÔºåËßÜÈ¢ëÈöæÁÇπÂâñÊûêÔºå5...</td>\n",
       "      <td>5</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>milvus-io / milvus</td>\n",
       "      <td>An open source embedding vector similarity sea...</td>\n",
       "      <td>136</td>\n",
       "      <td>Go 43.4% C++ 34.6% Python 16.3% CMake 2.9% She...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Haixiang6123 / one-day-one-npm-lib</td>\n",
       "      <td>ËøôÊú¨Â∞è‰π¶‰ºöÂ∏¶‰Ω†ÈÄ† 10 ‰∏™ÈùûÂ∏∏ÂÆûÁî®ÁöÑ npm Â∫ì üì¶</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aurasphere / gomorra-sql</td>\n",
       "      <td>SQL made uagli√≤.</td>\n",
       "      <td>2</td>\n",
       "      <td>Java 100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>audacity / audacity</td>\n",
       "      <td>Audio Editor</td>\n",
       "      <td>126</td>\n",
       "      <td>C 48.6% C++ 19.8% Python 13.2% Shell 7.4% Make...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>trimstray / the-book-of-secret-knowledge</td>\n",
       "      <td>A collection of inspiring lists, manuals, chea...</td>\n",
       "      <td>80</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pbatard / rufus</td>\n",
       "      <td>The Reliable USB Formatting Utility</td>\n",
       "      <td>93</td>\n",
       "      <td>C 89.2% Makefile 6.7% C# 1.4% C++ 1.1% Assembl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>streamich / react-use</td>\n",
       "      <td>React Hooks ‚Äî üëç</td>\n",
       "      <td>164</td>\n",
       "      <td>TypeScript 99.4% JavaScript 0.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PharkMillups / beautiful-docs</td>\n",
       "      <td>Pointers to useful, well-written, and otherwis...</td>\n",
       "      <td>63</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LeCoupa / awesome-cheatsheets</td>\n",
       "      <td>üë©‚Äçüíªüë®‚Äçüíª Awesome cheatsheets for popular program...</td>\n",
       "      <td>95</td>\n",
       "      <td>JavaScript 53.0% CSS 18.6% Shell 15.0% PHP 9.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>alacritty / alacritty</td>\n",
       "      <td>A cross-platform, OpenGL terminal emulator.</td>\n",
       "      <td>330</td>\n",
       "      <td>Rust 97.6% Shell 1.4% Other\\n1.0% Other 1.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sdmg15 / Best-websites-a-programmer-should-visit</td>\n",
       "      <td>üîó Some useful websites for programmers.</td>\n",
       "      <td>210</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>alibaba / Sentinel</td>\n",
       "      <td>A powerful flow control component enabling rel...</td>\n",
       "      <td>143</td>\n",
       "      <td>Java 89.4% JavaScript 5.5% HTML 3.9% CSS 1.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>jlevy / the-art-of-command-line</td>\n",
       "      <td>Master the command line, in one page</td>\n",
       "      <td>162</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>dromara / shenyu</td>\n",
       "      <td>High-Performance Java API Gateway</td>\n",
       "      <td>153</td>\n",
       "      <td>Java 99.4% Other\\n0.6% Other 0.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ruanyf / weekly</td>\n",
       "      <td>ÁßëÊäÄÁà±Â•ΩËÄÖÂë®ÂàäÔºåÊØèÂë®‰∫îÂèëÂ∏É</td>\n",
       "      <td>25</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>alibaba / canal</td>\n",
       "      <td>ÈòøÈáåÂ∑¥Â∑¥ MySQL binlog Â¢ûÈáèËÆ¢ÈòÖ&amp;Ê∂àË¥πÁªÑ‰ª∂</td>\n",
       "      <td>136</td>\n",
       "      <td>Java 94.3% Vue 2.2% JavaScript 1.5% Shell 1.1%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>nextapps-de / winbox</td>\n",
       "      <td>WinBox is a professional HTML5 window manager ...</td>\n",
       "      <td>2</td>\n",
       "      <td>JavaScript 82.5% Less 17.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>kelseyhightower / nocode</td>\n",
       "      <td>The best way to write secure and reliable appl...</td>\n",
       "      <td>0</td>\n",
       "      <td>Dockerfile 100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>kcp-dev / kcp</td>\n",
       "      <td>kcp is a prototype of a Kubernetes API server ...</td>\n",
       "      <td>8</td>\n",
       "      <td>Go 82.3% Shell 16.9% Makefile 0.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>apache / iceberg</td>\n",
       "      <td>Apache Iceberg</td>\n",
       "      <td>143</td>\n",
       "      <td>Java 90.6% Python 7.6% Scala 1.6% Other\\n0.2% ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Repository title  \\\n",
       "0   abuanwar072 / Flutter-Responsive-Admin-Panel-o...   \n",
       "1                                     pyston / pyston   \n",
       "2                                   slidevjs / slidev   \n",
       "3                     pallupz / covid-vaccine-booking   \n",
       "4                   youngyangyang04 / leetcode-master   \n",
       "5                                  milvus-io / milvus   \n",
       "6                  Haixiang6123 / one-day-one-npm-lib   \n",
       "7                            aurasphere / gomorra-sql   \n",
       "8                                 audacity / audacity   \n",
       "9            trimstray / the-book-of-secret-knowledge   \n",
       "10                                    pbatard / rufus   \n",
       "11                              streamich / react-use   \n",
       "12                      PharkMillups / beautiful-docs   \n",
       "13                      LeCoupa / awesome-cheatsheets   \n",
       "14                              alacritty / alacritty   \n",
       "15   sdmg15 / Best-websites-a-programmer-should-visit   \n",
       "16                                 alibaba / Sentinel   \n",
       "17                    jlevy / the-art-of-command-line   \n",
       "18                                   dromara / shenyu   \n",
       "19                                    ruanyf / weekly   \n",
       "20                                    alibaba / canal   \n",
       "21                               nextapps-de / winbox   \n",
       "22                           kelseyhightower / nocode   \n",
       "23                                      kcp-dev / kcp   \n",
       "24                                   apache / iceberg   \n",
       "\n",
       "                               Repository description Contributors count  \\\n",
       "0   Responsive Admin Panel or Dashboard using Flutter                  0   \n",
       "1   A faster and highly-compatible implementation ...                  2   \n",
       "2   Presentation Slides for Developers (Public Bet...                 11   \n",
       "3   This very basic script can be used to automate...                 10   \n",
       "4   LeetCode Âà∑È¢òÊîªÁï•Ôºö200ÈÅìÈ¢òÁõÆËØ¶ÁªÜÂà∑È¢òÈ°∫Â∫èÔºåÂÖ±60wÂ≠óÁöÑËØ¶ÁªÜÂõæËß£ÔºåËßÜÈ¢ëÈöæÁÇπÂâñÊûêÔºå5...                  5   \n",
       "5   An open source embedding vector similarity sea...                136   \n",
       "6                          ËøôÊú¨Â∞è‰π¶‰ºöÂ∏¶‰Ω†ÈÄ† 10 ‰∏™ÈùûÂ∏∏ÂÆûÁî®ÁöÑ npm Â∫ì üì¶                  0   \n",
       "7                                    SQL made uagli√≤.                  2   \n",
       "8                                        Audio Editor                126   \n",
       "9   A collection of inspiring lists, manuals, chea...                 80   \n",
       "10                The Reliable USB Formatting Utility                 93   \n",
       "11                                    React Hooks ‚Äî üëç                164   \n",
       "12  Pointers to useful, well-written, and otherwis...                 63   \n",
       "13  üë©‚Äçüíªüë®‚Äçüíª Awesome cheatsheets for popular program...                 95   \n",
       "14        A cross-platform, OpenGL terminal emulator.                330   \n",
       "15            üîó Some useful websites for programmers.                210   \n",
       "16  A powerful flow control component enabling rel...                143   \n",
       "17               Master the command line, in one page                162   \n",
       "18                  High-Performance Java API Gateway                153   \n",
       "19                                      ÁßëÊäÄÁà±Â•ΩËÄÖÂë®ÂàäÔºåÊØèÂë®‰∫îÂèëÂ∏É                 25   \n",
       "20                        ÈòøÈáåÂ∑¥Â∑¥ MySQL binlog Â¢ûÈáèËÆ¢ÈòÖ&Ê∂àË¥πÁªÑ‰ª∂                136   \n",
       "21  WinBox is a professional HTML5 window manager ...                  2   \n",
       "22  The best way to write secure and reliable appl...                  0   \n",
       "23  kcp is a prototype of a Kubernetes API server ...                  8   \n",
       "24                                     Apache Iceberg                143   \n",
       "\n",
       "                                        Language used  \n",
       "0   Dart 82.7% Ruby 8.3% HTML 4.6% Swift 3.9% Othe...  \n",
       "1   Python 63.0% C 34.1% C++ 1.3% HTML 0.4% M4 0.4...  \n",
       "2   TypeScript 58.5% Vue 29.5% CSS 5.8% JavaScript...  \n",
       "3                                       Python 100.0%  \n",
       "4                                                   -  \n",
       "5   Go 43.4% C++ 34.6% Python 16.3% CMake 2.9% She...  \n",
       "6                                                   -  \n",
       "7                                         Java 100.0%  \n",
       "8   C 48.6% C++ 19.8% Python 13.2% Shell 7.4% Make...  \n",
       "9                                                   -  \n",
       "10  C 89.2% Makefile 6.7% C# 1.4% C++ 1.1% Assembl...  \n",
       "11                   TypeScript 99.4% JavaScript 0.6%  \n",
       "12                                                  -  \n",
       "13  JavaScript 53.0% CSS 18.6% Shell 15.0% PHP 9.2...  \n",
       "14       Rust 97.6% Shell 1.4% Other\\n1.0% Other 1.0%  \n",
       "15                                                  -  \n",
       "16      Java 89.4% JavaScript 5.5% HTML 3.9% CSS 1.2%  \n",
       "17                                                  -  \n",
       "18                  Java 99.4% Other\\n0.6% Other 0.6%  \n",
       "19                                                  -  \n",
       "20  Java 94.3% Vue 2.2% JavaScript 1.5% Shell 1.1%...  \n",
       "21                        JavaScript 82.5% Less 17.5%  \n",
       "22                                  Dockerfile 100.0%  \n",
       "23                 Go 82.3% Shell 16.9% Makefile 0.8%  \n",
       "24  Java 90.6% Python 7.6% Scala 1.6% Other\\n0.2% ...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rep = trending_rep() #Calling the Function and storing it in the variable.\n",
    "rep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape the details of top 100 songs on billiboard.com. Url = https://www.billboard.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_100():\n",
    "    \"\"\"Creating function that searches details of top 100 songs from billboard\"\"\"\n",
    "    \n",
    "    template = 'https://www.billboard.com/'#URL template for accessing the website.\n",
    "    driver=webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver.exe\") #Calling the Web Driver    \n",
    "\n",
    "    driver.get(template)#Opening with the URL template.\n",
    "    driver.maximize_window()#Maximize the Window.\n",
    "    \n",
    "    href = []#Creating href list to collect \"HOT 100\" href details.\n",
    "    for i in driver.find_elements_by_xpath(\"//li [@class = 'header__subnav__item']/a\"):\n",
    "        if i.text == 'HOT 100':\n",
    "            href.append(i.get_attribute('href'))\n",
    "        \n",
    "    driver.get(href[0])# Opening the Driver with the collected href detail.\n",
    "    \n",
    "    #Scraping the Song_name and storing it in the Song_name list.\n",
    "    Song_name = [i.text for i in driver.find_elements_by_xpath(\"// span [@class ='chart-element__information']/span[@ class= 'chart-element__information__song text--truncate color--primary']\")]\n",
    "    \n",
    "    #Scraping the Artist_name and storing it in the Artist_name list.\n",
    "    Artist_name = [i.text for i in driver.find_elements_by_xpath(\"// span [@class ='chart-element__information']/span[@ class= 'chart-element__information__artist text--truncate color--secondary']\")]\n",
    "    \n",
    "    #Scraping the Last_week_rank and storing it in the Last_week_rank list.\n",
    "    Last_week_rank = [i.text for i in driver.find_elements_by_xpath(\"//div[@class = 'chart-element__metas chart-element__metas--large display--flex flex--y-center']/div[@class = 'chart-element__meta text--center color--secondary text--last']\")]\n",
    "    \n",
    "    #Scraping the Peak_rank and storing it in the Peak_rank list.\n",
    "    Peak_rank = [i.text for i in driver.find_elements_by_xpath(\"//div[@class = 'chart-element__metas chart-element__metas--large display--flex flex--y-center']/div[@class = 'chart-element__meta text--center color--secondary text--peak']\")]\n",
    "    \n",
    "    #Scraping the Weeks_on_board and storing it in the Weeks_on_board list.\n",
    "    Weeks_on_board = [i.text for i in driver.find_elements_by_xpath(\"//div[@class = 'chart-element__metas chart-element__metas--large display--flex flex--y-center']/div[@class = 'chart-element__meta text--center color--secondary text--week']\")]\n",
    "    \n",
    "    driver.close()#Quiting the Driver post Scraping the Details Required.\n",
    "\n",
    "    #Creating a DataFrame withe the collected Details.\n",
    "    table = pd.DataFrame({\"Song_name\" : Song_name,\n",
    "                          \"Artist_name\" : Artist_name,\n",
    "                          \"Last_week_rank\" : Last_week_rank,\n",
    "                          \"Peak_rank\" : Peak_rank,\n",
    "                          \"Weeks_on_board\": Weeks_on_board})\n",
    "    return table #Retuting the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song_name</th>\n",
       "      <th>Artist_name</th>\n",
       "      <th>Last_week_rank</th>\n",
       "      <th>Peak_rank</th>\n",
       "      <th>Weeks_on_board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Save Your Tears</td>\n",
       "      <td>The Weeknd &amp; Ariana Grande</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Leave The Door Open</td>\n",
       "      <td>Silk Sonic (Bruno Mars &amp; Anderson .Paak)</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Peaches</td>\n",
       "      <td>Justin Bieber Featuring Daniel Caesar &amp; Giveon</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rapstar</td>\n",
       "      <td>Polo G</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Levitating</td>\n",
       "      <td>Dua Lipa Featuring DaBaby</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kiss Me More</td>\n",
       "      <td>Doja Cat Featuring SZA</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Montero (Call Me By Your Name)</td>\n",
       "      <td>Lil Nas X</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Astronaut In The Ocean</td>\n",
       "      <td>Masked Wolf</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Up</td>\n",
       "      <td>Cardi B</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Drivers License</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Song_name  \\\n",
       "0                 Save Your Tears   \n",
       "1             Leave The Door Open   \n",
       "2                         Peaches   \n",
       "3                         Rapstar   \n",
       "4                      Levitating   \n",
       "5                    Kiss Me More   \n",
       "6  Montero (Call Me By Your Name)   \n",
       "7          Astronaut In The Ocean   \n",
       "8                              Up   \n",
       "9                 Drivers License   \n",
       "\n",
       "                                      Artist_name Last_week_rank Peak_rank  \\\n",
       "0                      The Weeknd & Ariana Grande              6         1   \n",
       "1        Silk Sonic (Bruno Mars & Anderson .Paak)              2         1   \n",
       "2  Justin Bieber Featuring Daniel Caesar & Giveon              3         1   \n",
       "3                                          Polo G              1         1   \n",
       "4                       Dua Lipa Featuring DaBaby              5         5   \n",
       "5                          Doja Cat Featuring SZA              8         6   \n",
       "6                                       Lil Nas X              4         1   \n",
       "7                                     Masked Wolf              7         7   \n",
       "8                                         Cardi B              9         1   \n",
       "9                                  Olivia Rodrigo             10         1   \n",
       "\n",
       "  Weeks_on_board  \n",
       "0             20  \n",
       "1              8  \n",
       "2              6  \n",
       "3              3  \n",
       "4             30  \n",
       "5              3  \n",
       "6              5  \n",
       "7             11  \n",
       "8             12  \n",
       "9             16  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_100songs = top_100() #Calling the Function and assigning it to a variable.\n",
    "top_100songs.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape the details of Data science recruiters from naukri.com. Url = https://www.naukri.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Naukri_Recruiters():\n",
    "    \"\"\"Creating function that searches details of recruiters from Naukri.com\"\"\"\n",
    "    \n",
    "    template = 'https://www.naukri.com/' #URL template for accessing the website.\n",
    "    driver=webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver.exe\") #Calling the Web Driver    \n",
    "\n",
    "    driver.get(template) #Opening with the URL template.\n",
    "    driver.maximize_window() #Maximize the Window.\n",
    "    \n",
    "    #Creating the variable Recruiters to search and find the Xpath of Recruiters.\n",
    "    Recruiters = driver.find_element_by_xpath(\"//li/a [@title = 'Search Recruiters']\") \n",
    "    href= Recruiters.get_attribute('href') #Creating the variable href to search and find the href of Recruiters.\n",
    "    driver.get(href) #Opening web-Driver with href.\n",
    "    \n",
    "    #Searching the input key and sending the key as Data Science.\n",
    "    search = driver.find_element_by_xpath(\"//div[@class= 'inpWrap']/ input [@class = 'sugInp']\")\n",
    "    search.send_keys(\"Data science\")\n",
    "    \n",
    "    #Searching the search Button and Clicking it.\n",
    "    search_btn = driver.find_element_by_xpath(\"//button[@class = 'fl qsbSrch blueBtn']\")\n",
    "    search_btn.click()\n",
    "    \n",
    "    #Creating a dummy list and storing details of name and Company of Recuriters.\n",
    "    dummy = [i.text for i in driver.find_elements_by_xpath(\"//p [@class ='highlightable']//a[@class = 'ellipsis']\")]\n",
    "    \n",
    "    #Creating href list and storing details of href of Recuriters.\n",
    "    href = [i.get_attribute('href') for i in driver.find_elements_by_xpath(\"//p [@class ='highlightable']//a[@class = 'ellipsis']\")]\n",
    "    \n",
    "    #Creating Designation list and storing details of Designation of Recuriters.\n",
    "    Designation = [i.text for i in driver.find_elements_by_xpath(\"//p [@class ='highlightable']//span[@ class= 'ellipsis clr']\")]\n",
    "    \n",
    "    #Creating skills list and storing details of skills of Recuriters.\n",
    "    skills = [i.text for i in driver.find_elements_by_xpath(\"//div [@class ='recInfo']//div[@ class= 'hireSec highlightable']\")]\n",
    "\n",
    "\n",
    "    Name = []#Creating a Name list to collect names of recuriters.\n",
    "    company = []#Creating a company list to collect company of recuriters.\n",
    "    Href = []#Creating a Href list to collect href of recuriters.\n",
    "    \n",
    "    z = 0 #Spliting dummy and href and storing it in the appropiate list.\n",
    "    while z < len(dummy):\n",
    "        Name.append(dummy[z])\n",
    "        Href.append(href[z])\n",
    "        z+=1\n",
    "        company.append(dummy[z])\n",
    "        z+=1\n",
    "    \n",
    "    Location = [] #creating the Location list to store all the location of the recuriters.\n",
    "    for i in Href: #iterating Href to collect the location details.\n",
    "        driver.get(i)\n",
    "        loc = [i.text for i in driver.find_elements_by_xpath(\"//div [@class ='oh']/a[@ target= '_blank']\")]\n",
    "        loc = loc[-1]\n",
    "        if loc == 'Others':\n",
    "            Location.append('-')\n",
    "        elif loc:\n",
    "            Location.append(loc)\n",
    "        else:\n",
    "            Location.append('-')\n",
    "   \n",
    "    driver.quit()#exiting the driver post scraping the information\n",
    "    \n",
    "    #Creating a DataFrame with all collected details.\n",
    "    table = pd.DataFrame({\"Name\" : Name,\n",
    "                          \"Company\" : company,\n",
    "                          \"Designation\" : Designation,\n",
    "                          \"Location\" : Location,\n",
    "                          \"skills\": skills})\n",
    "    \n",
    "    return table #returning the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Company</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Location</th>\n",
       "      <th>skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Classic ASP Developer, Internet Marketing Prof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>Shore Infotech India Pvt. Ltd</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "      <td>.Net, Java, Data Science, Linux Administration...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Talent Acquisition Executive</td>\n",
       "      <td>XenonStack</td>\n",
       "      <td>Recruitment Professional</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>Web Designing, html5, Angular.js, seo, hadoop,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anik Agrawal</td>\n",
       "      <td>Enerlytics Software Solutions Pvt Ltd</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>Mean Stack, javascript, angularjs, mongodb, We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Data Science, Artificial Intelligence, Machine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>subhas patel</td>\n",
       "      <td>LibraryXProject</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>UK - (london)</td>\n",
       "      <td>Hadoop, Spark, Digital Strategy, Data Architec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Abhishek - Only Analytics Hiring - India and</td>\n",
       "      <td>Apidel Technologies Division of Transpower</td>\n",
       "      <td>Recruitment Lead Consultant</td>\n",
       "      <td>Vadodara / Baroda</td>\n",
       "      <td>Analytics, Business Intelligence, Business Ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Institute for Financial Management and Resear</td>\n",
       "      <td>IFMR</td>\n",
       "      <td>Programme Manager</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Balu Ramesh</td>\n",
       "      <td>Techvantage Systems Pvt Ltd</td>\n",
       "      <td>HR Administrator</td>\n",
       "      <td>Trivandrum</td>\n",
       "      <td>Machine Learning, algorithms, Go Getter, Compu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Asif Lucknowi</td>\n",
       "      <td>Weupskill- Live Wire India</td>\n",
       "      <td>Director</td>\n",
       "      <td>Indore</td>\n",
       "      <td>Technical Training, Software Development, Pres...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Name  \\\n",
       "0                                   Aakash Harit   \n",
       "1                           shravan Kumar Gaddam   \n",
       "2                   Talent Acquisition Executive   \n",
       "3                                   Anik Agrawal   \n",
       "4                       MARSIAN Technologies LLP   \n",
       "5                                   subhas patel   \n",
       "6   Abhishek - Only Analytics Hiring - India and   \n",
       "7  Institute for Financial Management and Resear   \n",
       "8                                    Balu Ramesh   \n",
       "9                                  Asif Lucknowi   \n",
       "\n",
       "                                      Company                  Designation  \\\n",
       "0                        Data Science Network                   HR Manager   \n",
       "1               Shore Infotech India Pvt. Ltd            Company Recruiter   \n",
       "2                                  XenonStack     Recruitment Professional   \n",
       "3       Enerlytics Software Solutions Pvt Ltd            Company Recruiter   \n",
       "4                    MARSIAN Technologies LLP                   Company HR   \n",
       "5                             LibraryXProject                  Founder CEO   \n",
       "6  Apidel Technologies Division of Transpower  Recruitment Lead Consultant   \n",
       "7                                        IFMR            Programme Manager   \n",
       "8                 Techvantage Systems Pvt Ltd             HR Administrator   \n",
       "9                  Weupskill- Live Wire India                     Director   \n",
       "\n",
       "                   Location                                             skills  \n",
       "0                     Delhi  Classic ASP Developer, Internet Marketing Prof...  \n",
       "1  Hyderabad / Secunderabad  .Net, Java, Data Science, Linux Administration...  \n",
       "2                Chandigarh  Web Designing, html5, Angular.js, seo, hadoop,...  \n",
       "3                 Ahmedabad  Mean Stack, javascript, angularjs, mongodb, We...  \n",
       "4                      Pune  Data Science, Artificial Intelligence, Machine...  \n",
       "5             UK - (london)  Hadoop, Spark, Digital Strategy, Data Architec...  \n",
       "6         Vadodara / Baroda  Analytics, Business Intelligence, Business Ana...  \n",
       "7                   Chennai                                       Data Science  \n",
       "8                Trivandrum  Machine Learning, algorithms, Go Getter, Compu...  \n",
       "9                    Indore  Technical Training, Software Development, Pres...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Recruiters = Naukri_Recruiters() #calling function and storing it in a variable.\n",
    "Recruiters.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape the details of Highest selling novels. Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Highest_selling_novels():\n",
    "    \"\"\"The Function which searches and returns top selling novels from theguardian.com\"\"\"\n",
    "    \n",
    "    #URL template for accessing the website.\n",
    "    template = 'https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/'\n",
    "    driver=webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver.exe\") #Calling the Web Driver    \n",
    "\n",
    "    driver.get(template)#Opening with the URL template.\n",
    "    driver.maximize_window()#Maximize the Window.\n",
    "    \n",
    "    #Creating a dummy list and scraping the all the required details.\n",
    "    dummy = [i.text for i in driver.find_elements_by_xpath(\"//table [@class ='in-article sortable']//tr/td\")]\n",
    "    \n",
    "    driver.close() #Quiting the driver post collecting the details. \n",
    "    \n",
    "    dummy.remove('SOURCE: NIELSEN BOOK SCAN') #Removing the unwanted details from dummy list. \n",
    "\n",
    "    Book_name = [] #Creating list Book_name to collect the Book_name details.\n",
    "    Author_name = [] #Creating list Author_name to collect the Author_name details.\n",
    "    Volumes_sold = [] #Creating list Volumes_sold to collect the Volumes_sold details.\n",
    "    Publisher = [] #Creating list Publisher to collect the Publisher details.\n",
    "    Genre = [] #Creating list Genre to collect the Genre details.\n",
    "\n",
    "    z = 0\n",
    "    while z < len(dummy): #Splitting dummy list and storing the required details it in the appropriate list.\n",
    "        z+=1\n",
    "        Book_name.append(dummy[z])\n",
    "        z+=1\n",
    "        Author_name.append(dummy[z])\n",
    "        z+=1\n",
    "        Volumes_sold.append(dummy[z])\n",
    "        z+=1\n",
    "        Publisher.append(dummy[z])\n",
    "        z+=1\n",
    "        Genre.append(dummy[z])\n",
    "        z+=1\n",
    "    \n",
    "    #Creating the DataFrame with all the collected details.\n",
    "    table = pd.DataFrame({\"Book_name\" : Book_name,\n",
    "                          \"Author_name\" : Author_name,\n",
    "                          \"Volumes_sold\" : Volumes_sold,\n",
    "                          \"Publisher\" : Publisher,\n",
    "                          \"Genre\": Genre})\n",
    "    \n",
    "    return table #returning the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book_name</th>\n",
       "      <th>Author_name</th>\n",
       "      <th>Volumes_sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book_name       Author_name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes_sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Highest_selling_novels()#calling the Function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape the details most watched tv series of all time from imdb.com. Url = https://www.imdb.com/list/ls095964455/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostwatched_tv_series():\n",
    "    \n",
    "    template = 'https://www.imdb.com/list/ls095964455/' #URL template for accessing the website.\n",
    "    driver=webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver.exe\") #Calling the Web Driver    \n",
    "\n",
    "    driver.get(template) #Opening with the URL template.\n",
    "    driver.maximize_window() #Maximize the Window.\n",
    "    \n",
    "    #Creating the list Name and scraping the name of TV shows.\n",
    "    Name = [i.text for i in driver.find_elements_by_xpath(\"//h3 [@class ='lister-item-header']/a\")]\n",
    "    \n",
    "    #Creating the list Year_span and scraping the Year_span of TV shows.\n",
    "    Year_span = [i.text for i in driver.find_elements_by_xpath(\"//h3 [@class ='lister-item-header']/span[@class = 'lister-item-year text-muted unbold']\")]\n",
    "    \n",
    "    #Creating the list Genre and scraping the Genre of TV shows.\n",
    "    Genre = [i.text for i in driver.find_elements_by_xpath(\"//p [@class ='text-muted text-small']/span[@class = 'genre']\")]\n",
    "    \n",
    "    #Creating the list Run_time and scraping the Run_time of TV shows.\n",
    "    Run_time = [i.text for i in driver.find_elements_by_xpath(\"//p [@class ='text-muted text-small']/span[@class = 'runtime']\")]\n",
    "    \n",
    "    #Creating the list Ratings and scraping the Ratings of TV shows.\n",
    "    Ratings = [i.text for i in driver.find_elements_by_xpath(\"//div [@class ='ipl-rating-star small']/span[@class = 'ipl-rating-star__rating']\")]\n",
    "    \n",
    "    #Creating the list Votes and scraping the Votes of TV shows.\n",
    "    Votes = [i.text for i in driver.find_elements_by_xpath(\"//p [@class ='text-muted text-small']/span[@name = 'nv']\")]\n",
    "    \n",
    "    driver.quit()#exiting the driver post scraping the information\n",
    "    \n",
    "    #Creating a Dataframe with all collected details.\n",
    "    table = pd.DataFrame({\"Name\" : Name,\n",
    "                          \"Year_span\" : Year_span,\n",
    "                          \"Genre\" : Genre,\n",
    "                          \"Run_time\" : Run_time,\n",
    "                          \"Ratings\": Ratings,\n",
    "                          \"Votes\" : Votes})\n",
    "    \n",
    "    return table #Returning the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year_span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run_time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011‚Äì2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1,804,619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016‚Äì )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>849,350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010‚Äì2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>868,602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017‚Äì2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>260,487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014‚Äì2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>221,505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013‚Äì2017)</td>\n",
       "      <td>Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>44,257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017‚Äì2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>54,708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005‚Äì2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>165,721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015‚Äì2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.2</td>\n",
       "      <td>34,620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>188,540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year_span                     Genre  \\\n",
       "0                  Game of Thrones  (2011‚Äì2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016‚Äì )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010‚Äì2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017‚Äì2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014‚Äì2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013‚Äì2017)            Drama, Fantasy   \n",
       "96  A Series of Unfortunate Events  (2017‚Äì2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds  (2005‚Äì2020)     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015‚Äì2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run_time Ratings      Votes  \n",
       "0    57 min     9.3  1,804,619  \n",
       "1    51 min     8.7    849,350  \n",
       "2    44 min     8.2    868,602  \n",
       "3    60 min     7.6    260,487  \n",
       "4    43 min     7.6    221,505  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.5     44,257  \n",
       "96   50 min     7.8     54,708  \n",
       "97   42 min     8.1    165,721  \n",
       "98   45 min     7.2     34,620  \n",
       "99  572 min     8.6    188,540  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostwatched_tv_series() #calling the Function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Details of Datasets from UCI machine learning repositories. Url = https://archive.ics.uci.edu/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UCI_Repository():\n",
    "    \"\"\"The Function that Search all the ML Repository details and return them in DataFrame\"\"\"\n",
    "\n",
    "    template = 'https://archive.ics.uci.edu/' #URL template for accessing the website.\n",
    "    driver=webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver.exe\") #Calling the Web Driver    \n",
    "\n",
    "    \n",
    "    driver.get(template) #Opening with the URL template.\n",
    "    driver.maximize_window() #Maximize the Window.\n",
    "    time.sleep(3)#making the function to wait for 3sec\n",
    "    \n",
    "    #finding view all repository and clicking the same.\n",
    "    ml_repository = driver.find_element_by_xpath(\"//span [@class ='normal']/b/a\")\n",
    "    ml_repository.click()\n",
    "    \n",
    "    #creating a dummy list 'details' and scraping Dataset_name, Data_type, Task, Attribute_type, Noof_instances, Noof_attribute, Year.\n",
    "    details = [i.text for i in driver.find_elements_by_xpath(\"//table [@border ='1']/tbody/tr/td\")]\n",
    "    del details[:7] #Removing the unwanted details.\n",
    "    \n",
    "    driver.close() #Closing the Driver post scraping the details.\n",
    "    \n",
    "    Dataset_name = [] #creating list Dataset_name to collect Dataset_name. \n",
    "    Data_type = [] #creating list Data_type to collect Data_type. \n",
    "    Task = [] #creating list Task to collect Task. \n",
    "    Attribute_type = [] #creating list Attribute_type to collect Attribute_type. \n",
    "    Noof_instances = [] #creating list Noof_instances to collect Noof_instances. \n",
    "    Noof_attribute = [] #creating list Noof_attribute to collect Noof_attribute. \n",
    "    Year = [] #creating list Year to collect Year. \n",
    "\n",
    "    z= 0\n",
    "    while z < len(details): #Splitting the Dummy variable and storing it in a appropriate list.\n",
    "        Dataset_name.append(details[z])\n",
    "        z +=1\n",
    "\n",
    "        Data_type.append(details[z])\n",
    "        z +=1\n",
    "    \n",
    "        Task.append(details[z])\n",
    "        z +=1\n",
    "\n",
    "        Attribute_type.append(details[z])\n",
    "        z +=1\n",
    "\n",
    "        Noof_instances.append(details[z])\n",
    "        z +=1\n",
    "    \n",
    "        Noof_attribute.append(details[z])\n",
    "        z +=1\n",
    "\n",
    "        Year.append(details[z])\n",
    "        z +=1\n",
    "        \n",
    "        \n",
    "    #Creating DataFrame with collected Details    \n",
    "    table = pd.DataFrame({\"Dataset_name\" : Dataset_name,\n",
    "                          \"Data_type\" : Data_type,\n",
    "                          \"Task\" : Task,\n",
    "                          \"Attribute_type\" : Attribute_type,\n",
    "                          \"Noof_instances\" : Noof_instances,\n",
    "                          \"Noof_attribute\" : Noof_attribute,\n",
    "                          \"Year\" : Year})\n",
    "        \n",
    "    table = table.replace(' ', '-')\n",
    "        \n",
    "    return table #returning the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: unknown error: net::ERR_CONNECTION_TIMED_OUT\n  (Session info: chrome=89.0.4389.114)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-6d745e0b8ad6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mUCI_Repository\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUCI_Repository\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Calling the function and storing it in a variable.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mUCI_Repository\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-48-912f8f56f283>\u001b[0m in \u001b[0;36mUCI_Repository\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Opening with the URL template.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize_window\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Maximize the Window.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#making the function to wait for 3sec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[0mLoads\u001b[0m \u001b[0ma\u001b[0m \u001b[0mweb\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mbrowser\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \"\"\"\n\u001b[1;32m--> 333\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'url'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: unknown error: net::ERR_CONNECTION_TIMED_OUT\n  (Session info: chrome=89.0.4389.114)\n"
     ]
    }
   ],
   "source": [
    "UCI_Repository = UCI_Repository() #Calling the function and storing it in a variable.\n",
    "UCI_Repository.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
